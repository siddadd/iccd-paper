@article{Lowe2004,
author = {Lowe, David G.},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Lowe\_Distinctive Image Features from Scale-Invariant Keypoints\_2004.pdf:pdf},
issn = {0920-5691},
journal = {IJCV},
month = nov,
number = {2},
pages = {91--110},
title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
volume = {60},
year = {2004}
}

@article{Benoit2010,
author = {Benoit, A. and Caplier, A. and Durette, B. and Herault, J.},
doi = {10.1016/j.cviu.2010.01.011},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Benoit et al.\_Using Human Visual System modeling for bio-inspired low level image processing\_2010.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = jul,
number = {7},
pages = {758--773},
publisher = {Elsevier Inc.},
title = {{Using Human Visual System modeling for bio-inspired low level image processing}},
volume = {114},
year = {2010}
}

@article{Karam2011,
author = {Karam, L. and Sadaka, N. and Ferzli, R and Ivanovski, Z},
doi = {10.1109/TIP.2011.2159324},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Karam et al.\_An efficient selective perceptual-based super-resolution estimator.\_2011.pdf:pdf},
issn = {1941-0042},
journal = {IEEE Trans. on image processing},
month = dec,
number = {12},
pages = {3470--82},
pmid = {21672677},
title = {{An efficient selective perceptual-based super-resolution estimator.}},
volume = {20},
year = {2011}
}

@article{Giachetti1998,
author = {Giachetti, A. and Campani, M. and Torre, V.},
doi = {10.1109/70.660838},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Giachetti, Campani, Torre\_The use of optical flow for road navigation\_1998.pdf:pdf},
issn = {1042296X},
journal = {IEEE Transi. on Robotics and Automation},
number = {1},
pages = {34--48},
title = {{The use of optical flow for road navigation}},
volume = {14},
year = {1998}
}

@article{Hou2011,
author = {Hou, X. and Harel, J. and Koch, C.},
doi = {10.1109/TPAMI.2011.146},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Hou, Harel, Koch\_Image Signature Highlighting Sparse Salient Regions.\_2011.pdf:pdf},
issn = {1939-3539},
journal = {PAMI},
month = jul,
title = {{Image Signature: Highlighting Sparse Salient Regions.}},
year = {2011}
}

@article{Lang2012,
author = {Lang, Congyan and Liu, Guangcan and Yu, Jian and Yan, Shuicheng},
doi = {10.1109/TIP.2011.2169274},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Saliency Detection by Multitask Sparsity Pursuit.pdf:pdf},
issn = {1941-0042},
journal = {IEEE Trans. on Image Processing},
title = {{Saliency Detection by Multitask Sparsity Pursuit}},
year = {2012}
}

@article{Collins,
author = {Collins, R.},
doi = {10.1109/CVPR.2003.1211475},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Collins\_Mean-shift blob tracking through scale space\_Unknown.pdf:pdf},
isbn = {0-7695-1900-8},
journal = {CVPR},
title = {{Mean-shift blob tracking through scale space}},
}

@article{Judd2011,
author = {Judd, T. and Durand, F. and Torralba, A.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Judd Fixations on Low Res Images Poster.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
pmid = {21518823},
title = {{Fixations on Low-Resolution Images.}},
year = {2011}
}

@inproceedings{Delaluz2002,
author = {Delaluz, V. and Sivasubramaniam, A. and Kandemir, M. and Vijaykrishnan, N. and Irwin, M.J.},
booktitle = {DAC},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/DRAM\_dac02.pdf:pdf},
isbn = {1-58113-461-4},
keywords = {dram,energy management,operating systems,scheduler},
title = {{Scheduler-based DRAM energy management}},
year = {2002}
}

@article{Xu2010,
author = {Xu, J. and Yang, Z. and Tsien, J.},
doi = {10.1371/journal.pone.0015796},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Emergence of Visual Saliency from Natural Scenes via Context-Mediated Probability Distributions Coding.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
mendeley-tags = {Saliency},
number = {12},
title = {{Emergence of visual saliency from natural scenes via context-mediated probability distributions coding.}},
year = {2010}
}

@inproceedings{Mishra2009,
author = {Mishra, A. and Aloimonos, Y.},
booktitle = {ICCV},
doi = {10.1109/ICCV.2009.5459254},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/iccv2009\_activeSeg.pdf:pdf},
isbn = {978-1-4244-4420-5},
keywords = {fixation},
mendeley-tags = {fixation},
title = {{Active segmentation with fixation}},
year = {2009}
}

@article{Wolfe2004,
author = {Wolfe, J. and Horowitz, T.},
doi = {10.1038/nrn1411},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/WhatAttributesGuidetheDeploymentofSaliency.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
mendeley-tags = {Saliency},
pmid = {15152199},
title = {{What attributes guide the deployment of visual attention and how do they do it?}},
year = {2004}
}

@article{Daugman1985,
author = {Daugman, J.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Daugman Uncertainty.pdf:pdf},
journal = {Journal of the Optical Society of America},
title = {{Uncertainty Relation for Resolution in Space, Spatial Frequency, and Orientation Optimized by Two-Dimensional Visual Cortical Filters}},
year = {1985}
}

@inproceedings{Park2012,
author = {Park, S. and others},
booktitle = {ASPDAC},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/A reconfigurable platform for the design and verification of domain-specific accelerators.pdf:pdf},
isbn = {9781467307727},
title = {{A Reconfigurable Platform for the Design and Verification of Domain-Specific Accelerators}},
year = {2012}
}

@article{Burgsteiner2006,
author = {Burgsteiner, H. and others},
doi = {10.1007/s10489-006-0007-1},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Burgsteiner et al.\_Movement prediction from real-world images using a liquid state machine\_2006.pdf:pdf},
issn = {0924-669X},
journal = {Applied Intelligence},
title = {{Movement prediction from real-world images using a liquid state machine}},
year = {2006}
}

@inproceedings{Kestur2011,
author = {Kestur, S. and Dantara, D. and Narayanan, V.},
booktitle = {Design, Automation, and Test in Europe},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/MDL\_SHARC- A streaming model for FPGA accelerators and its application to Saliency.pdf:pdf},
isbn = {9783981080179},
keywords = {FPGA,Saliency},
mendeley-tags = {FPGA,Saliency},
title = {{SHARC : A Streaming Model for FPGA Accelerators and its Application to Saliency}},
year = {2011}
}

@inproceedings{Liu2011,
author = {Liu, S. and {Pattabiraman K.} and Moscibroda, T. and Zorn, B. },
booktitle = {ASLPOS},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Flikker.pdf:pdf},
isbn = {9781450302661},
keywords = {critical,dram refresh,power-savings,soft errors},
title = {{Flikker : Saving DRAM Refresh-power through Critical Data Partitioning}},
year = {2011}
}

@article{Rosenfeld2011,
author = {Rosenfeld, P and Cooper-Balis, E and Jacob, B},
doi = {10.1109/L-CA.2011.4},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/DRAMSim2.pdf:pdf},
issn = {1556-6056},
journal = {IEEE Computer Architecture Letters},
month = jan,
number = {1},
pages = {16--19},
title = {{DRAMSim2: A Cycle Accurate Memory System Simulator}},
volume = {10},
year = {2011}
}

@article{Tatler2011,
author = {Tatler, Benjamin W and Hayhoe, Mary M and Land, Michael F and Ballard, Dana H},
doi = {10.1167/11.5.5.Introduction},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Tatler et al.\_Eye guidance in natural vision Reinterpreting salience\_2011.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,11,1167,2011,23,5,Saliency,b,ballard,citation,content,d,doi,eye guidance in natural,eye movements,f,h,hayhoe,http,journal of vision,journalofvision,land,learning,m,natural tasks,org,prediction,reinterpreting,reward,salience,tatler,vision,w,www},
mendeley-tags = {Saliency},
pages = {1--23},
title = {{Eye Guidance in Natural Vision : Reinterpreting Salience}},
volume = {11},
year = {2011}
}

@article{Kuchnio2011,
author = {Kuchnio, Peter and Capson, David},
doi = {10.1109/CRV.2011.22},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Kuchnio, Capson\_GPU-Accelerated Foveation for Video Frame Rate Tracking\_2011.pdf:pdf},
isbn = {978-1-61284-430-5},
journal = {2011 Canadian Conference on Computer and Robot Vision},
keywords = {-gpu,algorithm in cuda are,cuda,details of,discussed in section iii,foveation,image-based visual servo,mapping of a foveated,motion segmentation,optical flow,scription of the parallel},
month = may,
pages = {117--124},
publisher = {Ieee},
title = {{GPU-Accelerated Foveation for Video Frame Rate Tracking}},
year = {2011}
}

@book{Land2009,
author = {Land, Michael F and Tatler, Benjamin W},
booktitle = {Psychology Press},
keywords = {Micheal F. Land and Benjamin W. Tatler,Vision},
mendeley-tags = {Vision},
publisher = {Oxford},
title = {{Looking and Acting: Vision and eye movements in natural behaviour}},
year = {2009}
}

@inproceedings{Farhadi2010,
author = {Farhadi, Ali and Hejrati, Mohsen and Sadeghi, Mohammad Amin and Young, Peter and Rashtchian, Cyrus and Hockenmaier, Julia and Forsyth, David},
booktitle = {European Conference on Computer Vision},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/sentence.pdf:pdf},
keywords = {scene},
mendeley-tags = {scene},
title = {{Every Picture Tells a Story : Generating Sentences from Images}},
year = {2010}
}

@article{Wal1992,
author = {Wal, Gooitzen S. and Burt, Peter J.},
doi = {10.1007/BF00055150},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Wal, Burt\_A VLSI pyramid chip for multiresolution image analysis\_1992.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = sep,
number = {3},
pages = {177--189},
title = {{A VLSI pyramid chip for multiresolution image analysis}},
volume = {8},
year = {1992}
}

@article{Judd2009,
author = {Judd, Tilke and Ehinger, Krista and Durand, Fredo and Torralba, Antonio},
doi = {10.1109/ICCV.2009.5459462},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Judd Learning to Predict Where Humans Look Poster.pdf:pdf},
isbn = {978-1-4244-4420-5},
journal = {2009 IEEE 12th International Conference on Computer Vision},
month = sep,
pages = {2106--2113},
publisher = {Ieee},
title = {{Learning to Predict Where Humans Look}},
year = {2009}
}

@techreport{Mutch2010,
address = {Cambridge, MA},
author = {Mutch, Jim and Knoblich, Ulf and Poggio, Tomaso},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/MIT-CSAIL-TR-2010-013.pdf:pdf},
institution = {Massachusetts Institute of Technology},
keywords = {GPU},
mendeley-tags = {GPU},
title = {{CNS : a GPU-based framework for simulating cortically-organized networks}},
year = {2010}
}

@inproceedings{Judd2009a,
author = {Judd, Tilke and Ehinger, Krista and Torralba, Antonio},
booktitle = {2009 IEEE 12th International Conference on Computer Vision},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Juddwherepeoplelook.pdf:pdf},
keywords = {Saliency},
mendeley-tags = {Saliency},
pages = {2106--2113},
title = {{Learning to Predict Where Humans Look}},
year = {2009}
}

@article{Mutch2008,
author = {Mutch, Jim and Lowe, David G.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/ijcv2008\_mutch\_lowe.pdf:pdf},
journal = {IJCV},
keywords = {object},
mendeley-tags = {object},
title = {{Object class recognition and localization using sparse features with limited receptive fields}},
year = {2008}
}

@article{Jiang2012,
author = {Jiang, Zhuolin and Lin, Zhe and Davis, Larry S.},
doi = {10.1016/j.cviu.2012.02.004},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Jiang, Lin, Davis\_Class consistent k-means Application to face and action recognition\_2012.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = jun,
number = {6},
pages = {730--741},
publisher = {Elsevier Inc.},
title = {{Class consistent k-means: Application to face and action recognition}},
volume = {116},
year = {2012}
}

@article{Wolfe2002,
author = {Wolfe, Jeremy M},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Wolfe\_Visual Search\_2002.pdf:pdf},
pages = {1--41},
title = {{Visual Search}},
year = {2002}
}

@inproceedings{Liu2012,
author = {Liu, Jamie},
booktitle = {ISCA},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/RAIDR.pdf:pdf},
isbn = {9781467304764},
keywords = {dram},
mendeley-tags = {dram},
number = {c},
pages = {1--12},
title = {{RAIDR : Retention-Aware Intelligent DRAM Refresh}},
volume = {00},
year = {2012}
}

@article{Parkhurst2002,
abstract = {A biologically motivated computational model of bottom-up visual selective attention was used to examine the degree to which stimulus salience guides the allocation of attention. Human eye movements were recorded while participants viewed a series of digitized images of complex natural and artificial scenes. Stimulus dependence of attention, as measured by the correlation between computed stimulus salience and fixation locations, was found to be significantly greater than that expected by chance alone and furthermore was greatest for eye movements that immediately follow stimulus onset. The ability to guide attention of three modeled stimulus features (color, intensity and orientation) was examined and found to vary with image type. Additionally, the effect of the drop in visual sensitivity as a function of eccentricity on stimulus salience was examined, modeled, and shown to be an important determiner of attentional allocation. Overall, the results indicate that stimulus-driven, bottom-up mechanisms contribute significantly to attentional guidance under natural viewing conditions.},
author = {Parkhurst, Derrick and Law, Klinton and Niebur, Ernst},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Modeling the role of salience in the allocation of overt visual attention.pdf:pdf},
issn = {0042-6989},
journal = {Vision Research},
keywords = {Analysis of Variance,Attention,Attention: physiology,Biological,Computer Simulation,Eye Movements,Eye Movements: physiology,Female,Humans,Male,Models,Normal Distribution,Visual Perception,Visual Perception: physiology},
month = jan,
number = {1},
pages = {107--23},
pmid = {11804636},
title = {{Modeling the Role of Salience in the Allocation of Overt Visual Attention}},
volume = {42},
year = {2002}
}

@article{Bandera1989,
author = {Bandera, C. and Scott, P.D.},
doi = {10.1109/ICSMC.1989.71367},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Bandera, Scott\_Foveal machine vision systems\_1989.pdf:pdf},
journal = {Conference Proceedings., IEEE International Conference on Systems, Man and Cybernetics},
keywords = {Foveation},
mendeley-tags = {Foveation},
pages = {596--599},
publisher = {Ieee},
title = {{Foveal machine vision systems}},
year = {1989}
}

@article{Geisler1998,
author = {Geisler, Wilson S and Perry, Jeffrey S},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/ARealTimeFoveatedMRSystemforLowBWVideoCommunication.pdf:pdf},
journal = {Proceedings of the SPIE: The International Society for Optical Engineering},
keywords = {Foveation,eye tracking,foveated imaging,foveation,human,motion compensation,multiresolution pyramid,video,video compression,vision,zero-tree coding},
mendeley-tags = {Foveation},
title = {{A Real-Time Foveated Multiresolution System for Low-Bandwidth Video Communication}},
volume = {3299},
year = {1998}
}

@article{Deng2009,
author = {Deng, L. and Chakrabarti, C. and Pitsianis, N. and Sun, X.},
doi = {10.1117/12.834184},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Deng et al.\_Automated optimization of look-up table implementation for function evaluation on FPGAs\_2009.pdf:pdf},
journal = {Proceedings of SPIE},
keywords = {automatic generation,fpgas,function evaluation,look-up table,resource minimization},
pages = {744413--744413--9},
publisher = {Spie},
title = {{Automated optimization of look-up table implementation for function evaluation on FPGAs}},
year = {2009}
}

@article{Young1998,
abstract = {This paper presents a method for detecting and classifying a target from its foveal (graded resolution) imagery using a multiresolution neural network. Target identification decisions are based on minimizing an energy function. This energy function is evaluated by comparing a candidate blob with a library of target models at several levels of resolution simultaneously available in the current foveal image. For this purpose, a concurrent (top-down-and-bottom-up) matching procedure is implemented via a novel multilayer Hopfield neural network. The associated energy function supports not only interactions between cells at the same resolution level, but also between sets of nodes at distinct resolution levels. This permits features at different resolution levels to corroborate or refute one another contributing to an efficient evaluation of potential matches. Gaze control, refoveation to more salient regions of the available image space, is implemented as a search for high resolution features which will disambiguate the candidate blob. Tests using real two-dimensional (2-D) objects and their simulated foveal imagery are provided.},
author = {Young, S S and Scott, P D and Bandera, C},
doi = {10.1109/83.704306},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Young, Scott, Bandera\_Foveal automatic target recognition using a multiresolution neural network.\_1998.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = jan,
number = {8},
pages = {1122--35},
pmid = {18276329},
title = {{Foveal automatic target recognition using a multiresolution neural network.}},
volume = {7},
year = {1998}
}

@article{Hrabar2005,
author = {Hrabar, S. and Sukhatme, G.S. and Corke, P. and Usher, K. and Roberts, J.},
doi = {10.1109/IROS.2005.1544998},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Hrabar et al.\_Combined optic-flow and stereo-based navigation of urban canyons for a UAV\_2005.pdf:pdf},
isbn = {0-7803-8912-3},
journal = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems},
pages = {3309--3316},
publisher = {Ieee},
title = {{Combined optic-flow and stereo-based navigation of urban canyons for a UAV}},
year = {2005}
}

@article{Riche2012,
author = {Riche, Nicolas and Mancas, Matei and Culibrk, Dubravko and Crnojevic, Vladimir and Gosselin, Bernard and Dutoit, Thierry},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Dynamic saliency models and human attention- a comparative study on videos.pdf:pdf},
journal = {Proceedings of the 11th Asian Conference on Computer Vision (ACCV)},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{Dynamic saliency models and human attention : a comparative study on videos}},
year = {2012}
}

@article{Itti2001,
abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
author = {Itti, L and Koch, C},
doi = {10.1038/35058500},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Itti\_Koch\_ComputationalModellingVisualAttention.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Attention,Attention: physiology,Computer Simulation,Humans,Models,Neurological,Neurons,Neurons: metabolism,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
pmid = {11256080},
title = {{Computational Modelling of Visual Attention}},
year = {2001}
}

@article{Thevenaz2000,
abstract = {Based on the theory of approximation, this paper presents a unified analysis of interpolation and resampling techniques. An important issue is the choice of adequate basis functions. We show that, contrary to the common belief, those that perform best are not interpolating. By opposition to traditional interpolation, we call their use generalized interpolation; they involve a prefiltering step when correctly applied. We explain why the approximation order inherent in any basis function is important to limit interpolation artifacts. The decomposition theorem states that any basis function endowed with approximation order can be expressed as the convolution of a B-spline of the same order with another function that has none. This motivates the use of splines and spline-based functions as a tunable way to keep artifacts in check without any significant cost penalty. We discuss implementation and performance issues, and we provide experimental evidence to support our claims.},
author = {Th\'{e}venaz, P and Blu, T and Unser, M},
doi = {10.1109/42.875199},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Th\'{e}venaz, Blu, Unser\_Interpolation revisited.\_2000.pdf:pdf},
issn = {0278-0062},
journal = {IEEE transactions on medical imaging},
keywords = {Artifacts,Costs and Cost Analysis,Diagnostic Imaging,Diagnostic Imaging: economics,Diagnostic Imaging: methods,Fourier Analysis,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Mathematics},
month = jul,
number = {7},
pages = {739--58},
pmid = {11055789},
title = {{Interpolation revisited.}},
volume = {19},
year = {2000}
}

@article{Bolduc1998,
author = {Bolduc, Marc and Levine, Martin D.},
doi = {10.1006/cviu.1997.0560},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Bolduc, Levine\_A Review of Biologically Motivated Space-Variant Data Reduction Models for Robotic Vision\_1998.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = feb,
number = {2},
pages = {170--184},
title = {{A Review of Biologically Motivated Space-Variant Data Reduction Models for Robotic Vision}},
volume = {69},
year = {1998}
}

@article{Vijayakumar2001,
author = {Vijayakumar, S. and Conradt, J. and Shibata, T. and Schaal, S.},
doi = {10.1109/IROS.2001.976418},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Vijayakumar et al.\_Overt visual attention for a humanoid robot\_2001.pdf:pdf},
isbn = {0-7803-6612-3},
journal = {Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180)},
number = {Iros},
pages = {2332--2337},
publisher = {Ieee},
title = {{Overt visual attention for a humanoid robot}},
volume = {4},
year = {2001}
}

@article{Land2000,
abstract = {In cricket, a batsman watches a fast bowler's ball come toward him at a high and unpredictable speed, bouncing off ground of uncertain hardness. Although he views the trajectory for little more than half a second, he can accurately judge where and when the ball will reach him. Batsmen's eye movements monitor the moment when the ball is released, make a predictive saccade to the place where they expect it to hit the ground, wait for it to bounce, and follow its trajectory for 100-200 ms after the bounce. We show how information provided by these fixations may allow precise prediction of the ball's timing and placement. Comparing players with different skill levels, we found that a short latency for the first saccade distinguished good from poor batsmen, and that a cricket player's eye movement strategy contributes to his skill in the game.},
author = {Land, M F and McLeod, P},
doi = {10.1038/81887},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/From eye movements to actions- how batsmen hit the ball.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Adult,Baseball,Baseball: physiology,Head Movements,Head Movements: physiology,Humans,Male,Motion Perception,Motion Perception: physiology,Motor Skills,Motor Skills: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Pursuit,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Smooth,Smooth: physiology,Sports,Sports: physiology,Vision},
mendeley-tags = {Vision},
month = dec,
number = {12},
pages = {1340--5},
pmid = {11100157},
title = {{From eye movements to actions: how batsmen hit the ball.}},
volume = {3},
year = {2000}
}

@article{Lehmann1999,
abstract = {Image interpolation techniques often are required in medical imaging for image generation (e.g., discrete back projection for inverse Radon transform) and processing such as compression or resampling. Since the ideal interpolation function spatially is unlimited, several interpolation kernels of finite size have been introduced. This paper compares 1) truncated and windowed sinc; 2) nearest neighbor; 3) linear; 4) quadratic; 5) cubic B-spline; 6) cubic; g) Lagrange; and 7) Gaussian interpolation and approximation techniques with kernel sizes from 1 x 1 up to 8 x 8. The comparison is done by: 1) spatial and Fourier analyses; 2) computational complexity as well as runtime evaluations; and 3) qualitative and quantitative interpolation error determinations for particular interpolation tasks which were taken from common situations in medical image processing. For local and Fourier analyses, a standardized notation is introduced and fundamental properties of interpolators are derived. Successful methods should be direct current (DC)-constant and interpolators rather than DC-inconstant or approximators. Each method's parameters are tuned with respect to those properties. This results in three novel kernels, which are introduced in this paper and proven to be within the best choices for medical image interpolation: the 6 x 6 Blackman-Harris windowed sinc interpolator, and the C2-continuous cubic kernels with N = 6 and N = 8 supporting points. For quantitative error evaluations, a set of 50 direct digital X rays was used. They have been selected arbitrarily from clinical routine. In general, large kernel sizes were found to be superior to small interpolation masks. Except for truncated sinc interpolators, all kernels with N = 6 or larger sizes perform significantly better than N = 2 or N = 3 point methods (p < 0.005). However, the differences within the group of large-sized kernels were not significant. Summarizing the results, the cubic 6 x 6 interpolator with continuous second derivatives, as defined in (24), can be recommended for most common interpolation tasks. It appears to be the fastest six-point kernel to implement computationally. It provides eminent local and Fourier properties, is easy to implement, and has only small errors. The same characteristics apply to B-spline interpolation, but the 6 x 6 cubic avoids the intrinsic border effects produced by the B-spline technique. However, the goal of this study was not to determine an overall best method, but to present a comprehensive catalogue of methods in a uniform terminology, to define general properties and requirements of local techniques, and to enable the reader to select that method which is optimal for his specific application in medical imaging.},
author = {Lehmann, T M and G\"{o}nner, C and Spitzer, K},
doi = {10.1109/42.816070},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Lehmann, G\"{o}nner, Spitzer\_Survey interpolation methods in medical image processing.\_1999.pdf:pdf},
issn = {0278-0062},
journal = {IEEE transactions on medical imaging},
keywords = {Diagnostic Imaging,Fourier Analysis,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods},
month = nov,
number = {11},
pages = {1049--75},
pmid = {10661324},
title = {{Survey: interpolation methods in medical image processing.}},
volume = {18},
year = {1999}
}

@article{Einhauser2003,
author = {Einhauser, Wolfgang and Konig, Peter},
doi = {10.1046/j.1460-9568.2003.02508.x},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Einhauser, Konig\_Does luminance-contrast contribute to a saliency map for overt visual attention\_2003.pdf:pdf},
issn = {0953-816X},
journal = {European Journal of Neuroscience},
keywords = {eye movements,hierarchy,human,top-down,visual system},
month = mar,
number = {5},
pages = {1089--1097},
title = {{Does luminance-contrast contribute to a saliency map for overt visual attention?}},
volume = {17},
year = {2003}
}

@inproceedings{Liu2013,
author = {Liu, Jamie and Jaiyen, Ben and Kim, Yoongu and Wilkerson, Chris},
booktitle = {International Symposium on Computer Architecture},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/dram-retention\_isca13.pdf:pdf},
isbn = {9781450320795},
title = {{An Experimental Study of Data Retention Behavior in Modern DRAM Devices : Implications for Retention Time Profiling Mechanisms}},
year = {2013}
}

@article{Karam2012,
author = {Karam, Samuel F . Dodge and Lina J .},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/gesture\_ICIP2012\_cameraready\_final.pdf:pdf},
journal = {International Conference on Image Processing},
title = {{Attentive gesture recognition}},
year = {2012}
}

@article{DeBole2011,
author = {DeBole, M. and Maashri, a. Al and Cotter, M. and Yu, C-L. and Chakrabarti, C. and Narayanan, V.},
doi = {10.1109/ICCAD.2011.6105351},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/DeBole et al.\_A framework for accelerating neuromorphic-vision algorithms on FPGAs\_2011.pdf:pdf},
isbn = {978-1-4577-1400-9},
journal = {2011 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
keywords = {- multi-fpga partitioning,fpga application mapping,fpga programming,neuromorphic vision algorithms},
month = nov,
pages = {810--813},
publisher = {Ieee},
title = {{A framework for accelerating neuromorphic-vision algorithms on FPGAs}},
year = {2011}
}

@article{Jablin2009,
author = {Jablin, Thomas and Upton, Dan and August, David and Hazelwood, Kim and Mahlke, Scott},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/multicore compilation strategies and challenges.pdf:pdf},
journal = {IEEE Signal Processing Magazine},
keywords = {Compiler},
mendeley-tags = {Compiler},
number = {November},
pages = {55--63},
title = {{Multicore Compilation Strategies and Challenges [}},
year = {2009}
}

@article{Bruce2006,
author = {Bruce, Neil D B and Tsotsos, John K},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Bruce\_Saliency Based on Information Maximization.pdf\_Unknown.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {155--162},
title = {{Saliency Based on Information Maximization}},
volume = {18},
year = {2006}
}

@techreport{Judd2012,
author = {Judd, T. and Durand, F. and Torralba, A.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Judd, Durand, Torralba\_A Benchmark of Computational Models of Saliency to Predict Human Fixations A Benchmark of Computational Models of Saliency to Predict Human Fixations\_2012.pdf:pdf},
institution = {Massachusetts Institute of Technology},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{A Benchmark of Computational Models of Saliency to Predict Human Fixations}},
year = {2012}
}

@inproceedings{Nere2011,
author = {Nere, A. and Hashmi, A. and Lipasti, M.},
booktitle = {IPDPS},
doi = {10.1109/IPDPS.2011.88},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/nere\_ipdps\_2011.pdf:pdf},
isbn = {978-1-61284-372-8},
keywords = {-cortical learning algorithms,gpgpu,profiling},
title = {{Profiling Heterogeneous Multi-GPU Systems to Accelerate Cortically Inspired Learning Algorithms}},
year = {2011}
}

@article{Grzyb2009,
author = {Grzyb, B. and Chinellato, E. and Wojcik, G. and Kaminski, W.},
doi = {10.1109/IJCNN.2009.5179025},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Grzyb et al.\_Facial expression recognition based on Liquid State Machines built of alternative neuron models\_2009.pdf:pdf},
isbn = {978-1-4244-3548-7},
journal = {2009 Int. Joint Conf. on Neural Networks},
title = {{Facial expression recognition based on Liquid State Machines built of alternative neuron models}},
year = {2009}
}

@article{Burt1983,
author = {Burt, P. and Adelson, E.},
doi = {10.1145/245.247},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Burt, Adelson\_A multiresolution spline with application to image mosaics\_1983.pdf:pdf},
issn = {07300301},
journal = {ACM Trans. on Graphics},
title = {{A multiresolution spline with application to image mosaics}},
year = {1983}
}

@article{Verstraeten2005,
author = {Verstraeten, D. and Schrauwen, B. and Stroobandt, D. and {Van Campenhout}, J.},
doi = {10.1016/j.ipl.2005.05.019},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Verstraeten et al.\_Isolated word recognition with the Liquid State Machine a case study\_2005.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {liquid state machine,parallel processing,speech recognition,spiking neural networks},
month = sep,
number = {6},
pages = {521--528},
title = {{Isolated word recognition with the Liquid State Machine: a case study}},
volume = {95},
year = {2005}
}

@article{Chen2006,
author = {Chen, G. and Xue, L. and Kim, J. and Sobti, K. and Deng, L. and Sun, X. and Pitsianis, N. and Chakrabarti, C. and Kandemir, M. and Vijaykrishnan, N.},
doi = {10.1109/SOCC.2006.283861},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Chen et al.\_Geometric Tiling for Reducing Power Consumption in Structured Matrix Operations\_2006.pdf:pdf},
isbn = {0-7803-9782-7},
journal = {2006 IEEE International SOC Conference},
month = sep,
pages = {113--114},
publisher = {Ieee},
title = {{Geometric Tiling for Reducing Power Consumption in Structured Matrix Operations}},
year = {2006}
}

@inproceedings{Venkatesh2011,
author = {Venkatesh, Ganesh and Sampson, Jack and Goulding-hotta, Nathan and Venkata, Sravanthi Kota and Taylor, Michael Bedford and Swanson, Steven},
booktitle = {IEEE Micro},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Micro2011QASICS.pdf:pdf},
isbn = {9781450310536},
keywords = {Dark Silicon,conservation core,dark silicon,heterogeneous many-core,merging,q s c ore,specialization,utilization,wall},
mendeley-tags = {Dark Silicon},
title = {{QSCORES : Trading Dark Silicon for Scalable Energy Efficiency with Quasi-Specific Cores}},
year = {2011}
}

@article{Walther2006,
abstract = {Selective visual attention is believed to be responsible for serializing visual information for recognizing one object at a time in a complex scene. But how can we attend to objects before they are recognized? In coherence theory of visual cognition, so-called proto-objects form volatile units of visual information that can be accessed by selective attention and subsequently validated as actual objects. We propose a biologically plausible model of forming and attending to proto-objects in natural scenes. We demonstrate that the suggested model can enable a model of object recognition in cortex to expand from recognizing individual objects in isolation to sequentially recognizing all objects in a more complex scene.},
author = {Walther, Dirk and Koch, Christof},
doi = {10.1016/j.neunet.2006.10.001},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Walther, Koch\_Modeling attention to salient proto-objects.\_2006.pdf:pdf},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {Attention,Biological,Computer Simulation,Discrimination Learning,Discrimination Learning: physiology,Feedback,Humans,Models,Neural Networks (Computer),Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,ROC Curve,Visual,Visual: physiology},
month = nov,
number = {9},
pages = {1395--407},
pmid = {17098563},
title = {{Modeling Attention to Salient Proto-objects}},
volume = {19},
year = {2006}
}

@article{Vo2008,
author = {V\~{o}, Melissa L and Schneider, Werner X and Matthias, Ellen},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/vo\_2008\_jemr.pdf:pdf},
journal = {Journal of Eye Movement Research},
keywords = {Vision,processing efficiency,scene perception,theory of visual attention,transsaccadic memory,tva},
mendeley-tags = {Vision},
number = {2},
pages = {1--13},
title = {{Transsaccadic Scene Memory Revisited : A ' Theory of Visual Attention ( TVA )' Based Approach to Recognition Memory and Confidence for Objects in Naturalistic Scenes .}},
volume = {2},
year = {2008}
}

@article{Hu2014,
abstract = {About ten years ago, HMAX was proposed as a simple and biologically feasible model for object recognition, based on how the visual cortex processes information. However, the model does not encompass sparse firing, which is a hallmark of neurons at all stages of the visual pathway. The current paper presents an improved model, called sparse HMAX, which integrates sparse firing. This model is able to learn higher-level features of objects on unlabeled training images. Unlike most other deep learning models that explicitly address global structure of images in every layer, sparse HMAX addresses local to global structure gradually along the hierarchy by applying patch-based learning to the output of the previous layer. As a consequence, the learning method can be standard sparse coding (SSC) or independent component analysis (ICA), two techniques deeply rooted in neuroscience. What makes SSC and ICA applicable at higher levels is the introduction of linear higher-order statistical regularities by max pooling. After training, high-level units display sparse, invariant selectivity for particular individuals or for image categories like those observed in human inferior temporal cortex (ITC) and medial temporal lobe (MTL). Finally, on an image classification benchmark, sparse HMAX outperforms the original HMAX by a large margin, suggesting its great potential for computer vision.},
author = {Hu, Xiaolin and Zhang, Jianwei and Li, Jianmin and Zhang, Bo},
doi = {10.1371/journal.pone.0081813},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/SparseHMAX.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
month = jan,
number = {1},
pages = {e81813},
pmid = {24392078},
title = {{Sparsity-regularized HMAX for visual recognition.}},
volume = {9},
year = {2014}
}

@inproceedings{Nair2013,
author = {Nair, P. and Chou, C. and Qureshi, M.},
booktitle = {HPCA},
doi = {10.1109/HPCA.2013.6522355},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Refresh\_Pausing.pdf:pdf},
isbn = {978-1-4673-5587-2},
keywords = {refresh},
mendeley-tags = {refresh},
title = {{A case for Refresh Pausing in DRAM memory systems}},
year = {2013}
}

@article{Kunar2007,
abstract = {Contextual cuing experiments show that when displays are repeated, reaction times to find a target decrease over time even when observers are not aware of the repetition. It has been thought that the context of the display guides attention to the target. The authors tested this hypothesis by comparing the effects of guidance in a standard search task with the effects of contextual cuing. First, in standard search, an improvement in guidance causes search slopes (derived from Reaction Time x Set Size functions) to decrease. In contrast, the authors found that search slopes in contextual cuing did not become more efficient over time (Experiment 1). Second, when guidance was optimal (e.g., in easy feature search), they still found a small but reliable contextual cuing effect (Experiments 2a and 2b), suggesting that other factors, such as response selection, contribute to the effect. Experiment 3 supported this hypothesis by showing that the contextual cuing effect disappeared when the authors added interference to the response selection process. Overall, the data suggest that the relationship between guidance and contextual cuing is weak and that response selection can account for part of the effect.},
author = {Kunar, Melina a and Flusberg, Stephen and Horowitz, Todd S and Wolfe, Jeremy M},
doi = {10.1037/0096-1523.33.4.816},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Kunar et al.\_Does contextual cuing guide the deployment of attention\_2007.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Adolescent,Adult,Attention,Cues,Female,Humans,Male,Middle Aged,Reaction Time,Visual Perception},
month = aug,
number = {4},
pages = {816--28},
pmid = {17683230},
title = {{Does contextual cuing guide the deployment of attention?}},
volume = {33},
year = {2007}
}

@article{Crouzet2011,
abstract = {Research progress in machine vision has been very significant in recent years. Robust face detection and identification algorithms are already readily available to consumers, and modern computer vision algorithms for generic object recognition are now coping with the richness and complexity of natural visual scenes. Unlike early vision models of object recognition that emphasized the role of figure-ground segmentation and spatial information between parts, recent successful approaches are based on the computation of loose collections of image features without prior segmentation or any explicit encoding of spatial relations. While these models remain simplistic models of visual processing, they suggest that, in principle, bottom-up activation of a loose collection of image features could support the rapid recognition of natural object categories and provide an initial coarse visual representation before more complex visual routines and attentional mechanisms take place. Focusing on biologically plausible computational models of (bottom-up) pre-attentive visual recognition, we review some of the key visual features that have been described in the literature. We discuss the consistency of these feature-based representations with classical theories from visual psychology and test their ability to account for human performance on a rapid object categorization task.},
author = {Crouzet, S\'{e}bastien M and Serre, Thomas},
doi = {10.3389/fpsyg.2011.00326},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Serre\_What\_are\_the\_features\_underlying\_rapid\_object\_recognition.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {computational models,computer vision,feedforward,rapid visual object recognition,visual features},
month = jan,
number = {Nov},
pmid = {22110461},
title = {{What are the Visual Features Underlying Rapid Object Recognition?}},
volume = {2},
year = {2011}
}

@inproceedings{CarrollAaronHeiser2010,
author = {{Carroll, Aaron Heiser}, Gernot},
booktitle = {Usenix Annual Technical Conference (ATC)},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Carroll.pdf:pdf},
title = {{An Analysis of Power Consumption in a Smartphone}},
year = {2010}
}

@article{Rutishauser,
author = {Rutishauser, U. and Walther, D. and Koch, C. and Perona, P.},
doi = {10.1109/CVPR.2004.1315142},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Rutishauser et al.\_Is bottom-up attention useful for object recognition\_Unknown.pdf:pdf},
isbn = {0-7695-2158-4},
journal = {Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
pages = {37--44},
publisher = {Ieee},
title = {{Is bottom-up attention useful for object recognition?}},
volume = {2}
}

@inproceedings{Fergus2004,
author = {Fergus, R. and Perona, P.},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition Workshop on Generative-Model Based Vision},
doi = {10.1109/CVPR.2004.383},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Learning generative visual models from few training examples- an incremental Bayesian approach tested on 101 object categories.pdf:pdf},
keywords = {Object},
mendeley-tags = {Object},
pages = {178--178},
publisher = {Ieee},
title = {{Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories}},
year = {2004}
}

@inproceedings{Lee2013,
author = {Lee, Donghyuk and Kim, Yoongu and Seshadri, Vivek and Liu, Jamie and Subramanian, Lavanya and Mutlu, Onur},
booktitle = {2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA)},
doi = {10.1109/HPCA.2013.6522354},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Tiered-Latency DRAM- A Low Latency and Low Cost DRAM Architecture.pdf:pdf},
isbn = {978-1-4673-5587-2},
month = feb,
pages = {615--626},
publisher = {Ieee},
title = {{Tiered-latency DRAM: A low latency and low cost DRAM architecture}},
year = {2013}
}

@inproceedings{Kestur2012,
author = {Kestur, S and others},
booktitle = {FCCM},
doi = {10.1109/FCCM.2012.33},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/kestur\_neo2\_fccm2012.pdf:pdf},
isbn = {978-1-4673-1605-7},
keywords = {accelerator,fpga,hmax,neuromorphic,recognition,saliency,vision},
title = {{Emulating Mammalian Vision on Reconfigurable Hardware}},
year = {2012}
}

@article{Schomberg1995,
abstract = {The authors explore a computational method for reconstructing an n-dimensional signal f from a sampled version of its Fourier transform f;. The method involves a window function w; and proceeds in three steps. First, the convolution g;=w;*f; is computed numerically on a Cartesian grid, using the available samples of f;. Then, g=wf is computed via the inverse discrete Fourier transform, and finally f is obtained as g/w. Due to the smoothing effect of the convolution, evaluating w;*f; is much less error prone than merely interpolating f;. The method was originally devised for image reconstruction in radio astronomy, but is actually applicable to a broad range of reconstructive imaging methods, including magnetic resonance imaging and computed tomography. In particular, it provides a fast and accurate alternative to the filtered backprojection. The basic method has several variants with other applications, such as the equidistant resampling of arbitrarily sampled signals or the fast computation of the Radon (Hough) transform.},
author = {Schomberg, H and Timmer, J},
doi = {10.1109/42.414625},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Schomberg, Timmer\_The gridding method for image reconstruction by Fourier transformation.\_1995.pdf:pdf},
issn = {0278-0062},
journal = {IEEE transactions on medical imaging},
month = jan,
number = {3},
pages = {596--607},
pmid = {18215864},
title = {{The gridding method for image reconstruction by Fourier transformation.}},
volume = {14},
year = {1995}
}

@article{Rajashekar2008,
abstract = {The ability to automatically detect visually interesting regions in images has many practical applications, especially in the design of active machine vision and automatic visual surveillance systems. Analysis of the statistics of image features at observers' gaze can provide insights into the mechanisms of fixation selection in humans. Using a foveated analysis framework, we studied the statistics of four low-level local image features: luminance, contrast, and bandpass outputs of both luminance and contrast, and discovered that image patches around human fixations had, on average, higher values of each of these features than image patches selected at random. Contrast-bandpass showed the greatest difference between human and random fixations, followed by luminance-bandpass, RMS contrast, and luminance. Using these measurements, we present a new algorithm that selects image regions as likely candidates for fixation. These regions are shown to correlate well with fixations recorded from human observers.},
author = {Rajashekar, U and van der Linde, I and Bovik, a C and Cormack, L K},
doi = {10.1109/TIP.2008.917218},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Rajashekar et al.\_GAFFE a gaze-attentive fixation finding engine.\_2008.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Trans. on Image Processing},
keywords = {Algorithms,Artificial Intelligence,Attention,Attention: physiology,Automated,Automated: methods,Biological,Biomimetics,Biomimetics: methods,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Fixation,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Models,Ocular,Ocular: physiology,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Visual,Visual: physiology},
month = apr,
number = {4},
pages = {564--73},
pmid = {18390364},
title = {{GAFFE: A Gaze-Attentive Fixation Finding Engine}},
volume = {17},
year = {2008}
}

@article{Gupta2007,
author = {Gupta, Abhinav and Davis, Larry S and Park, College},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/cvpr\_2007.pdf:pdf},
journal = {IEEE Conference on Computer Vision and Pattern Recognition},
keywords = {scene},
mendeley-tags = {scene},
number = {2},
title = {{Objects in Action : An Approach for Combining Action Understanding and Object Perception}},
year = {2007}
}

@article{Advani2013,
author = {Advani, Siddharth and Sustersic, John and Irick, Kevin and Narayanan, Vijaykrishnan},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Advani\_ICASSP\_2013\_Paper.pdf:pdf},
journal = {IEEE Proceedings of The 38th International Conference on Acoustics, Speech, and Signal Processing},
keywords = {Foveation,Saliency},
mendeley-tags = {Foveation,Saliency},
title = {{A Multi-Resolution Saliency Framework To Drive Foveation}},
year = {2013}
}

@article{Azzopardi2012,
abstract = {Simple cells in primary visual cortex are believed to extract local contour information from a visual scene. The 2D Gabor function (GF) model has gained particular popularity as a computational model of a simple cell. However, it short-cuts the LGN, it cannot reproduce a number of properties of real simple cells, and its effectiveness in contour detection tasks has never been compared with the effectiveness of alternative models. We propose a computational model that uses as afferent inputs the responses of model LGN cells with center-surround receptive fields (RFs) and we refer to it as a Combination of Receptive Fields (CORF) model. We use shifted gratings as test stimuli and simulated reverse correlation to explore the nature of the proposed model. We study its behavior regarding the effect of contrast on its response and orientation bandwidth as well as the effect of an orthogonal mask on the response to an optimally oriented stimulus. We also evaluate and compare the performances of the CORF and GF models regarding contour detection, using two public data sets of images of natural scenes with associated contour ground truths. The RF map of the proposed CORF model, determined with simulated reverse correlation, can be divided in elongated excitatory and inhibitory regions typical of simple cells. The modulated response to shifted gratings that this model shows is also characteristic of a simple cell. Furthermore, the CORF model exhibits cross orientation suppression, contrast invariant orientation tuning and response saturation. These properties are observed in real simple cells, but are not possessed by the GF model. The proposed CORF model outperforms the GF model in contour detection with high statistical confidence (RuG data set: p<10(-4), and Berkeley data set: p<10(-4)). The proposed CORF model is more realistic than the GF model and is more effective in contour detection, which is assumed to be the primary biological role of simple cells.},
author = {Azzopardi, George and Petkov, Nicolai},
doi = {10.1007/s00422-012-0486-6},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/A CORF Computational Model of a simple cell that relies on LGN input outperforms the Gabor function model.pdf:pdf},
issn = {1432-0770},
journal = {Biological Cybernetics},
keywords = {Models,Neurons,Neurons: cytology,Theoretical,Visual Cortex,Visual Cortex: cytology},
month = mar,
number = {3},
pages = {177--89},
pmid = {22526357},
title = {{A CORF Computational Model of a Simple Cell that Relies on LGN Input Outperforms the Gabor Function Model}},
volume = {106},
year = {2012}
}

@article{Torralba2003,
abstract = {In this paper we study the statistical properties of natural images belonging to different categories and their relevance for scene and object categorization tasks. We discuss how second-order statistics are correlated with image categories, scene scale and objects. We propose how scene categorization could be computed in a feedforward manner in order to provide top-down and contextual information very early in the visual processing chain. Results show how visual categorization based directly on low-level features, without grouping or segmentation stages, can benefit object localization and identification. We show how simple image statistics can be used to predict the presence and absence of objects in the scene before exploring the image.},
author = {Torralba, Antonio and Oliva, Aude},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Torralba, Oliva\_Statistics of natural image categories.\_2003.pdf:pdf},
issn = {0954-898X},
journal = {Network (Bristol, England)},
keywords = {Nature,Photic Stimulation,Photic Stimulation: methods,Statistics as Topic},
month = aug,
number = {3},
pages = {391--412},
pmid = {12938764},
title = {{Statistics of natural image categories.}},
volume = {14},
year = {2003}
}

@article{Muller2006,
author = {M\"{u}ller, Hermann J. and Krummenacher, Joseph},
doi = {10.1080/13506280500527676},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/M\"{u}ller, Krummenacher\_Visual search and selective attention\_2006.pdf:pdf},
isbn = {1350628050},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {4-8},
pages = {389--410},
title = {{Visual search and selective attention}},
volume = {14},
year = {2006}
}

@article{Riesenhuber1999,
abstract = {Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function.},
author = {Riesenhuber, M and Poggio, T},
doi = {10.1038/14819},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Poggio\_Hierarchical\_models\_of\_object\_recognition\_in\_cortex.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Animals,Computer Simulation,Form Perception,Form Perception: physiology,Hierarchy,Macaca,Mental Recall,Mental Recall: physiology,Models,Neurological,Neurons,Neurons: physiology,Object,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology},
mendeley-tags = {Hierarchy,Object},
month = nov,
number = {11},
pages = {1019--25},
pmid = {10526343},
title = {{Hierarchical models of object recognition in cortex.}},
volume = {2},
year = {1999}
}

@article{Kunar2006,
abstract = {In visual search tasks, attention can be guided to a target item--appearing amidst distractors--on the basis of simple features (e.g., finding the red letter among green). Chun and Jiang's (1998) contextual cuing effect shows that reaction times (RTs) are also speeded if the spatial configuration of items in a scene is repeated over time. In the present studies, we ask whether global properties of the scene can speed search (e.g., if the display is mostly red, then the target is at location X). In Experiment 1A, the overall background color of the display predicted the target location, and the predictive color could appear 0, 400, or 800 msec in advance of the search array. Mean RTs were faster in predictive than in nonpredictive conditions. However, there was little improvement in search slopes. The global color cue did not improve search efficiency. Experiments 1B-1F replicated this effect using different predictive properties (e.g., background orientation-texture and stimulus color). The results showed a strong RT effect of predictive background, but (at best) only a weak improvement in search efficiency. A strong improvement in efficiency was found, however, when the informative background was presented 1,500 msec prior to the onset of the search stimuli and when observers were given explicit instructions to use the cue (Experiment 2).},
author = {Kunar, Melina a and Flusberg, Stephen J and Wolfe, Jeremy M},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Kunar, Flusberg, Wolfe\_Contextual cuing by global features.\_2006.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adolescent,Adult,Attention,Color Perception,Cues,Female,Field Dependence-Independence,Humans,Judgment,Male,Middle Aged,Orientation,Reaction Time},
month = oct,
number = {7},
pages = {1204--16},
pmid = {17355043},
title = {{Contextual cuing by global features.}},
volume = {68},
year = {2006}
}

@article{Goodrich2012,
author = {Goodrich, Ben and Arel, Itamar},
doi = {10.1109/CVPRW.2012.6239177},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Goodrich, Arel\_Reinforcement learning based visual attention with application to face detection\_2012.pdf:pdf},
isbn = {978-1-4673-1612-5},
journal = {2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
month = jun,
pages = {19--24},
publisher = {Ieee},
title = {{Reinforcement learning based visual attention with application to face detection}},
year = {2012}
}

@article{Bae2011,
author = {Bae, Sungmin and Cho, Yong Cheol Peter and Park, Sungho and Irick, Kevin M. and Jin, Yongseok and Narayanan, Vijaykrishnan},
doi = {10.1109/FCCM.2011.41},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/MDL\_An FPGA implementation of Information Theoretic Visual-Saliency System and Its Optimization.pdf:pdf},
isbn = {978-1-61284-277-6},
journal = {2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines},
keywords = {FPGA,Saliency},
mendeley-tags = {FPGA,Saliency},
month = may,
pages = {41--48},
publisher = {Ieee},
title = {{An FPGA Implementation of Information Theoretic Visual-Saliency System and Its Optimization}},
year = {2011}
}

@article{Traver2008,
author = {Traver, V. Javier and Pla, Filiberto},
doi = {10.1016/j.imavis.2007.11.009},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Traver, Pla\_Log-polar mapping template design From task-level requirements to geometry parameters\_2008.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {design criteria,genetic algorithm,log-polar vision,receptive fields},
title = {{Log-polar mapping template design: From task-level requirements to geometry parameters}},
year = {2008}
}

@article{Ghodrati2012,
abstract = {Humans can effectively and swiftly recognize objects in complex natural scenes. This outstanding ability has motivated many computational object recognition models. Most of these models try to emulate the behavior of this remarkable system. The human visual system hierarchically recognizes objects in several processing stages. Along these stages a set of features with increasing complexity is extracted by different parts of visual system. Elementary features like bars and edges are processed in earlier levels of visual pathway and as far as one goes upper in this pathway more complex features will be spotted. It is an important interrogation in the field of visual processing to see which features of an object are selected and represented by the visual cortex. To address this issue, we extended a hierarchical model, which is motivated by biology, for different object recognition tasks. In this model, a set of object parts, named patches, extracted in the intermediate stages. These object parts are used for training procedure in the model and have an important role in object recognition. These patches are selected indiscriminately from different positions of an image and this can lead to the extraction of non-discriminating patches which eventually may reduce the performance. In the proposed model we used an evolutionary algorithm approach to select a set of informative patches. Our reported results indicate that these patches are more informative than usual random patches. We demonstrate the strength of the proposed model on a range of object recognition tasks. The proposed model outperforms the original model in diverse object recognition tasks. It can be seen from the experiments that selected features are generally particular parts of target images. Our results suggest that selected features which are parts of target objects provide an efficient set for robust object recognition.},
author = {Ghodrati, M. and Khaligh-Razavi, S. and Ebrahimpour, R. and Rajaei, K. and Pooyan, M.},
doi = {10.1371/journal.pone.0032357},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Ghodrati\_BioinspiredFeatures.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Algorithms,Brain Mapping,Brain Mapping: methods,Computational Biology,Computational Biology: methods,Computer Simulation,Humans,Models, Statistical,Models, Theoretical,Normal Distribution,Pattern Recognition, Visual,Photic Stimulation,Photic Stimulation: methods,Recognition (Psychology),Vision, Ocular,Visual Pathways,Visual Perception},
title = {{How can selection of biologically inspired features improve the performance of a robust object recognition model?}},
year = {2012}
}

@article{Schrauwen,
abstract = {Hardware implementations of Spiking Neural Networks are numerous because they are well suited for implementation in digital and analog hardware, and outperform classic neural networks. This work presents an application driven digital hardware exploration where we implement real-time, isolated digit speech recognition using a Liquid State Machine. The Liquid State Machine is a recurrent neural network of spiking neurons where only the output layer is trained. First we test two existing hardware architectures which we improve and extend, but that appears to be too fast and thus area consuming for this application. Next, we present a scalable, serialized architecture that allows a very compact implementation of spiking neural networks that is still fast enough for real-time processing. All architectures support leaky integrate-and-fire membranes with exponential synaptic models. This work shows that there is actually a large hardware design space of Spiking Neural Network hardware that can be explored. Existing architectures have only spanned part of it.},
author = {Schrauwen, B. and D'Haene, M. and Verstraeten, D. and Van Campenhout, J.},
doi = {10.1016/j.neunet.2007.12.009},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Schrauwen et al.\_Compact hardware liquid state machines on FPGA for real-time speech recognition.\_Unknown.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks},
keywords = {Action Potentials,Analog-Digital Conversion,Humans,Models, Neurological,Neural Networks (Computer),Recognition (Psychology),Signal Processing, Computer-Assisted,Speech,Time Factors},
title = {{Compact hardware liquid state machines on FPGA for real-time speech recognition.}},
}

@inproceedings{Chen2014,
author = {Chen, T. and Wang, J. and Chen, Y. and Temam, O.},
booktitle = {ASPLOS},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/DianNao.pdf:pdf},
keywords = {Accelerator},
mendeley-tags = {Accelerator},
title = {{DianNao : A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning}},
year = {2014}
}

@phdthesis{Maashri2012,
author = {Maashri, A.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/maashri\_accelerated\_embedded\_vision\_systems\_v4.pdf:pdf},
title = {{Accelerating design and implementation of embedded vision systems}},
year = {2012}
}

@phdthesis{Dantara2011,
author = {Dantara, D.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Dharav\_Dantara\_MS\_Thesis.pdf:pdf},
keywords = {Accelerator},
mendeley-tags = {Accelerator},
school = {The Pennsylvania State University},
title = {{Reconfigurable Accelerators for Neuromorphic Systems}},
type = {MS Thesis},
year = {2011}
}

@article{Shu-Ying2009,
author = {Shu-Ying, Y. and WeiMin, G. and Cheng, Z.},
doi = {10.1016/j.visres.2008.11.002},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Shu-Ying, WeiMin, Cheng\_Tracking unknown moving targets on omnidirectional vision.\_2009.pdf:pdf},
journal = {Vision research},
title = {{Tracking unknown moving targets on omnidirectional vision.}},
year = {2009}
}

@article{Lleras2004,
author = {Lleras, A. and {Von M\"{u}hlenen}, A.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Lleras, Von M\"{u}hlenen\_Spatial context and top-down strategies in visual search.\_2004.pdf:pdf},
issn = {0169-1015},
journal = {Spatial vision},
keywords = {Adult,Attention,Cues,Female,Humans,Individuality,Male,Random Allocation,Reaction Time,Space Perception},
title = {{Spatial context and top-down strategies in visual search.}},
year = {2004}
}

@article{Bruceb,
author = {Bruce, N.},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{An Information Theoretic Model of Saliency and Visual Search}},
}

@article{Belongie2002,
author = {Belongie, S. and Malik, J. and Puzicha, J.},
doi = {10.1109/34.993558},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Belongie, Malik, Puzicha\_Shape matching and object recognition using shape contexts\_2002.pdf:pdf},
issn = {01628828},
journal = {IEEE Trans. on Pattern Analysis and Machine Intelligence},
month = apr,
number = {4},
pages = {509--522},
title = {{Shape matching and object recognition using shape contexts}},
volume = {5395},
year = {2009}
}

@misc{GodwinDwayne2012,
author = {{Godwin D.}, Cham J.},
booktitle = {Scientific American},
keywords = {brain},
mendeley-tags = {brain},
title = {{Your Brain by the Numbers}},
year = {2012}
}

@phdthesis{Kestur2012a,
author = {Kestur, S.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/1-SrinidhiKestur-Dissertation.pdf:pdf},
number = {May},
title = {{Domain-Specific Accelerators on Reconfigurable Platforms}},
year = {2012}
}

@inproceedings{Maashri2012a,
author = {Maashri, A. and others},
booktitle = {DAC},
doi = {10.1145/2228360.2228465},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/MDL\_neuromorphic\_dac12.pdf:pdf},
isbn = {9781450311991},
keywords = {Object,domain-specific,power efficiency,recognition,system},
mendeley-tags = {Object},
pages = {579},
publisher = {ACM Press},
title = {{Accelerating neuromorphic vision algorithms for recognition}},
year = {2012}
}

@inproceedings{Clemons2012,
author = {Clemons, Jason and Zhu, Haishan and Savarese, Silvio and Austin, Todd and Arbor, Ann},
booktitle = {IEEE International Symposium on Workload Characterization},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/MEVBench.pdf:pdf},
title = {{MEVBench : A Mobile Computer Vision Benchmarking Suite}},
year = {2012}
}

@article{Bruce2009a,
author = {Bruce, N. and Tsotsos, J.},
doi = {10.1167/9.3.5},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Bruce, Tsotsos\_Saliency, attention, and visual search an information theoretic approach.\_2009.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
language = {en},
mendeley-tags = {Saliency},
title = {{Saliency, Attention, and Visual Search: An Information Theoretic Approach}},
year = {2009}
}

@article{Yamamoto1996,
author = {Yamamoto, H. and Yeshurun, Y. and Levine, M.},
doi = {10.1006/cviu.1996.0004},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Yamamoto, Yeshurun, Levine\_An Active Foveated Vision System Attentional Mechanisms and Scan Path Covergence Measures\_1996.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
title = {{An Active Foveated Vision System: Attentional Mechanisms and Scan Path Covergence Measures}},
year = {1996}
}

@book{Gonzalez2007,
author = {Gonzalez, R. and Woods, R.},
isbn = {013168728X},
keywords = {Image Processing},
mendeley-tags = {Image Processing},
publisher = {Prentice Hall},
title = {{Digital Image Processing (3rd Edition)}},
year = {2007}
}

@inproceedings{Mukundan2013,
author = {Mukundan, J. and Hunter, H. and Kim, K-H and Stuecheli, J.},
booktitle = {ISCA},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/isca13-mukundan.pdf:pdf},
isbn = {9781450320795},
keywords = {refresh},
mendeley-tags = {refresh},
title = {{Understanding and Mitigating Refresh Overheads in High-Density DDR4 DRAM Systems}},
year = {2013}
}

@inproceedings{Stuecheli2010,
author = {Stuecheli, J and Kaseridis, D. and Hunter, H. and John, L.},
booktitle = {MICRO},
doi = {10.1109/MICRO.2010.22},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Elastic Refresh.pdf:pdf},
isbn = {978-1-4244-9071-4},
title = {{Elastic Refresh: Techniques to Mitigate Refresh Penalties in High Density Memory}},
year = {2010}
}

@article{Peters2007,
author = {Peters, R. and Itti, L.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Peters\_Itti08tap.pdf:pdf},
journal = {ACM Trans. on Applied Perception},
title = {{Applying computational tools to predict gaze direction in interactive visual environments}},
year = {2007}
}

@article{Schrauwen2008,
author = {Schrauwen, B. and D'Haene, M. and Verstraeten, D. and Van Campenhout, Jan},
doi = {10.1016/j.neunet.2007.12.009},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Schrauwen et al.\_Compact hardware liquid state machines on FPGA for real-time speech recognition.\_2008.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
title = {{Compact hardware liquid state machines on FPGA for real-time speech recognition.}},
year = {2008}
}

@article{Irick2009,
author = {Irick, K. and others},
doi = {10.1117/12.834177},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Irick et al.\_A scalable multi-FPGA framework for real-time digital signal processing\_2009.pdf:pdf},
journal = {Proceedings of SPIE},
keywords = {fpga design,image processing},
title = {{A scalable multi-FPGA framework for real-time digital signal processing}},
year = {2009}
}

@article{Guo2010,
author = {Guo, C. and Zhang, L.},
doi = {10.1109/TIP.2009.2030969},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Guo, Zhang\_A novel multiresolution spatiotemporal saliency detection model and its applications in image and video compression.\_2010.pdf:pdf},
issn = {1941-0042},
journal = {IEEE Trans. on Image Processing},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{A Novel Multiresolution Spatiotemporal Saliency Detection Model and its Applications in Image and Video Compression}},
year = {2010}
}

@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/The Mendeley Support Team\_Getting Started with Mendeley\_2011.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
year = {2011}
}

@article{Koehler2014,
author = {Koehler, K. and Eckstein, M.},
doi = {10.1167/14.3.14.doi},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/What do saliency models predict.pdf:pdf},
journal = {Journal of Vision},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{What do saliency models predict ?}},
year = {2014}
}

@misc{vivado,
      title  = "{Vivado Design Suite}",
      booktitle = "Xilinx",
      url = {http://www.xilinx.com/products/design-tools/vivado/},
      year   = "2014",
    }

@misc{jedec-sdram-standards,
      title  = "{JEDEC DDR3 and DDR4 SDRAM Standard}",
      booktitle = "JEDEC",
      year   = "2012",
    }


@article{Itti1998,
  author = {L. Itti and C. Koch and E. Niebur},
  title = {A Model of Saliency-Based Visual Attention for Rapid Scene Analysis},
  journal = {IEEE Trans. on Pattern Analysis and Machine Intelligence},
  year = {1998},
  keywords = {Visual attention ; target detection ; saliency ; image understanding},
  abstract = {A trainable visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.},
  type = {mod;bu;cv},
  file = {http://iLab.usc.edu/publications/doc/Itti_etal98pami.pdf},
  if = {1998 impact factor: 1.417},
}

@INPROCEEDINGS{Effex, 
author={Clemons, J. and Jones, A. and Perricone, R. and Savarese, S. and Austin, T.}, 
booktitle={Design Automation Conference (DAC), 2011 48th ACM/EDAC/IEEE}, 
title={EFFEX: An embedded processor for computer vision based feature extraction}, 
year={2011}, 
ISSN={0738-100x}}

@INPROCEEDINGS{Farabet, 
author={Farabet, C. and others}, 
booktitle={CVPRw}, 
title={NeuFlow: A runtime reconfigurable dataflow processor for vision}, 
year={2011}, 
keywords={computer vision;field programmable gate arrays;flow graphs;NeuFlow;Xilinx Virtex 6 FPGA platform;dataflow compiler;flow graph representations;laptop computer;luaFlow;machine code;runtime reconfigurable dataflow processor;scalable dataflow hardware architecture;Computer architecture;Convolvers;Feature extraction;Field programmable gate arrays;Hardware;Runtime;Tiles}, 
doi={10.1109/CVPRW.2011.5981829}, 
ISSN={2160-7508}}

@ARTICLE{DRAMSim2,
author={Rosenfeld, P. and Cooper-Balis, E. and Jacob, B.},
journal={Computer Architecture Letters}, 
title={DRAMSim2: A Cycle Accurate Memory System Simulator},
year={2011},
keywords={DDR2/3 memory system model;DRAMSim2 simulation;DRAMSim2 timing;Verilog model;cycle accurate memory system simulator;trace-based simulation;visualization tool;DRAM chips;memory architecture;memory cards;},
doi={10.1109/L-CA.2011.4},
ISSN={1556-6056},}


@INPROCEEDINGS{islped98, 
author={Ohsawa, T. and Kai, K. and Murakami, K.}, 
booktitle={ISLPED}, 
title={Optimizing the DRAM refresh count for merged DRAM/logic LSIs}, 
year={1998}, 
month={Aug}, 
pages={82-87}, 
keywords={DRAM chips;circuit optimisation;integrated circuit design;integrated logic circuits;large scale integration;low-power electronics;memory architecture;DRAM refresh architectures;DRAM refresh count optimisation;data retention time;merged DRAM/logic LSIs;power consumption},}

@INPROCEEDINGS{action-recognition, 
author={Jhuang, H. and Serre, T. and Wolf, L. and Poggio, T.}, 
booktitle={ICCV}, 
title={A Biologically Inspired System for Action Recognition}, 
year={2007}, 
month={Oct}, 
pages={1-8}, 
keywords={image motion analysis;image sequences;object recognition;video signal processing;action recognition;biologically inspired system;hierarchical feedforward architectures;motion processing;motion-direction sensitive units;neurobiological model;object recognition;position-invariant spatio-temporal feature detectors;video sequences;Biological system modeling;Brain modeling;Computer vision;Motion analysis;Motion detection;Object recognition;Position sensitive particle detectors;Sensor arrays;Testing;Video sequences}, 
doi={10.1109/ICCV.2007.4408988}, 
ISSN={1550-5499},}

@inproceedings{Weizmann,
  author	= {Moshe Blank and Lena Gorelick and Eli Shechtman and Michal Irani and Ronen Basri},
  title 	= {Actions as Space-Time Shapes},
  booktitle	= {ICCV},
  year   	= {2005},
  }

@article{refresh-pausing-taco2014,
 author = {Nair, P. and Chou, C. and Qureshi, M.},
 title = {Refresh Pausing in DRAM Memory Systems},
 journal = {TACO},
 year = {2014},
 doi = {10.1145/2579669},
} 


@INPROCEEDINGS{mcpat, 
author={Li, S. and others}, 
booktitle={MICRO}, 
title={{McPAT}: An integrated power, area, and timing modeling framework for multicore and manycore architectures}, 
year={2009}
}
