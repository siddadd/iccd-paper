Video applications are becoming ubiquitous in mobile and embedded systems. Wearable video systems such as Google glasses require capabilities for real-time video analytics and prolonged battery lifetimes for wide adoption. Further, the increasing resolution of image sensors in these mobile systems places an increasing demand on both the memory storage as well as the computational power. Consequently, there is growing interest in energy-efficient algorithms and hardware for video analytics. In this work, we present an embedded architecture for multi-object scene understanding and tackle the unique opportunities provided by real-time embedded video analytics applications for reducing the DRAM memory refresh energy. We compare our design with the existing design space. Results indicate the benefits of utilizing "smart" energy-efficient memories in next-generation real-time visual systems. 
